# Copyright (C) Deutsche Telekom AG
#
# Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
#
# 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#
"""NETCONF client
"""

import logging
import net
import process
import testing
import xml

import ssh_client

SEPARATOR_FRAMING: int = 0
CHUNKED_FRAMING: int = 1

CHUNK_SIZE_MAX: int = 4294967295

LEGACY_SEPARATOR: bytes = "]]>]]>".encode()

CHUNK_TAG_PREFIX: bytes = "\n#".encode()
CHUNK_TAG_END_OF_MSG: bytes = "#".encode()
CHUNK_TAG_POSTFIX: bytes = "\n".encode()

CAP_NC_1_1 = "urn:ietf:params:netconf:base:1.1"

NS_NC_1_0 = "urn:ietf:params:xml:ns:netconf:base:1.0"
NS_YANG_ACTION = "urn:ietf:params:xml:ns:yang:1"

# TODO: I think this should be in __builtin__
class UnreachableError(Exception):
    pass

# TODO: move these to __builtin__
class ConnectionError(OSError):
    pass

class BrokenPipeError(ConnectionError):
    pass

class ConnectionAbortedError(ConnectionError):
    pass

class ConnectionRefusedError(ConnectionError):
    pass

class ConnectionResetError(ConnectionError):
    pass

class NetconfError(Exception):
    pass

STATE_NONE          = 0
STATE_CONNECTING    = 1
STATE_CONNECTED     = 2
STATE_DISCONNECTING = 3

state_name = {
    STATE_NONE:          "none",
    STATE_CONNECTING:    "connecting",
    STATE_CONNECTED:     "connected",
    STATE_DISCONNECTING: "disconnecting"
}

actor Client(auth: WorldCap, address: str, port: int, username: str, password: ?str, key: ?str,
        on_connect: action(Client, ?Exception) -> None,
        on_notif: ?action(Client, xml.Node) -> None,
        log_handler: ?logging.Handler):

    _log = logging.Logger(log_handler)
    _log.info("Connecting to " + address + ":" + str(port) + " as " + username)

    var framing = SEPARATOR_FRAMING
    var recv_buf = Buffer()
    var chunk_buf = Buffer()

    var session_id: ?str = None
    var capabilities: list[str] = []

    # Tracks explicit namespace prefix usage in NETCONF messages.
    # Client mirrors server's namespace declaration pattern: defaults to
    # implicit namespace on root element, switches to explicit prefix on all
    # elements, including attributes, when detected in server responses. This is
    # not a strict requirement per RFC 6241, but it is expected by Junos running
    # RFC-compliant mode [1] - in particular the device will *not* include
    # message-id in the replies if the attribute is sent without an explicit
    # namespace prefix.
    #
    # We always use the "urn:ietf:params:xml:ns:netconf:base:1.0" namespace when
    # creating xml.Node for tags. The nsdefs tuple (nc_prefix, NS_NC_1_1)
    # renders to either the default or explicit namespace declaration depending
    # nc_prefix.
    #
    # [1]: (https://www.juniper.net/documentation/us/en/software/junos/netconf/topics/concept/netconf-session-rfc-compliant.html)
    var nc_prefix: ?str = None

    var message_id = 1
    var rpc_cbs: dict[str, action(Client, ?xml.Node) -> None] = {}

    var c: ?ssh_client.Client = None
    var state = STATE_NONE

    def get_capabilities() -> list[str]:
        return capabilities

    # TODO: Close protocol
    def close(cb: ?action() -> None) -> None:
        for rpc_cb in rpc_cbs.values():
            rpc_cb(self, None)
        #rpc_cbs.clear()
        rpc_cbs = {}

        if c is not None:
            c.close(cb)
        else:
            if cb is not None:
                cb()

    # TODO: Restart protocol
    def restart() -> None:
        _log.info("Restarting")
        for rpc_cb in rpc_cbs.values():
            rpc_cb(self, None)

        framing = SEPARATOR_FRAMING
        recv_buf = Buffer()
        chunk_buf = Buffer()

        session_id = None
        capabilities = []

        message_id = 1
        rpc_cbs = {}

        state = STATE_NONE

        if c is not None:
            c.restart()
        else:
            _log.warning("Cannot restart, SSH client is not running")

    def _send_message(data: Buffer) -> None:
        if c is not None:
            if framing == SEPARATOR_FRAMING:
                data.write_bytes(LEGACY_SEPARATOR)
                _msg = data.read_all_bytes()
                _log.trace("Sending message", {"msg": _msg})
                c.write(_msg)
            elif framing == CHUNKED_FRAMING:
                while True:
                    chunk_size = CHUNK_SIZE_MAX if data.unread_bytes > CHUNK_SIZE_MAX else data.unread_bytes
                    if chunk_size <= 0:
                        c.write("\n##\n".encode())
                        break

                    _chunk = data.read_bytes(chunk_size)
                    _log.trace("Sending chunk", {"chunk_size": chunk_size, "chunk": _chunk})
                    c.write(("\n#" + str(chunk_size) + "\n").encode())
                    c.write(_chunk)
        else:
            on_connect(self, BrokenPipeError("Cannot send message, SSH process is not running"))

    def rpc(content: xml.Node, callback: action(Client, ?xml.Node) -> None) -> None:
        message_id_text = str(message_id)
        message_id += 1

        # If using an explicit namespace prefix, prepend it to the attribute name.
        # The namespace (prefix or not) is defined in the tag.
        if nc_prefix is not None:
            rpc_attrs = [(nc_prefix + ":message-id", str(message_id_text))]
        else:
            rpc_attrs = [("message-id", str(message_id_text))]

        root = xml.Node("rpc", [(nc_prefix, NS_NC_1_0)], nc_prefix, rpc_attrs, [content])

        buf: Buffer = Buffer()
        buf.write_str(xml.encode(root))

        rpc_cbs[message_id_text] = callback
        _log.debug("Sending RPC", {"message-id": message_id_text, "content": content})
        _send_message(buf)

    def get(cb: action(Client, ?xml.Node) -> None, filter: ?xml.Node=None) -> None:
        _log.info("NETCONF get")
        nc_nsdefs = [(None, NS_NC_1_0)]
        children = []
        if filter is not None:
            children.append(filter)
        rpc(xml.Node("get", nc_nsdefs, children=children), cb)

    def get_config(cb: action(Client, ?xml.Node) -> None, datastore: str="running") -> None:
        _log.info("NETCONF get-config")
        nc_nsdefs = [(nc_prefix, NS_NC_1_0)]
        rpc(xml.Node("get-config", nc_nsdefs, nc_prefix, children=[
            xml.Node("source", [], nc_prefix, children=[
                xml.Node(datastore, [], nc_prefix)
            ]),
        ]), cb)

    def edit_config(config: str, cb: action(Client, ?xml.Node) -> None, datastore: str="running") -> None:
        _log.info("NETCONF edit-config", {"datastore": datastore})
        nc_nsdefs = [(nc_prefix, NS_NC_1_0)]
        rpc(xml.Node("edit-config", nc_nsdefs, nc_prefix, children=[
            xml.Node("target", [], nc_prefix, children=[
                xml.Node(datastore, [], nc_prefix)
            ]),
            xml.Node("config", [], nc_prefix, text=config)
        ]), cb)

    def commit(cb: action(Client, ?xml.Node) -> None) -> None:
        _log.info("NETCONF commit", {})
        nc_nsdefs = [(nc_prefix, NS_NC_1_0)]
        rpc(xml.Node("commit", nc_nsdefs, nc_prefix), cb)

    def discard_changes(cb: action(Client, ?xml.Node) -> None) -> None:
        _log.info("NETCONF discard-changes", {})
        nc_nsdefs = [(nc_prefix, NS_NC_1_0)]
        rpc(xml.Node("discard-changes", nc_nsdefs, nc_prefix), cb)

    def lock(cb: action(Client, ?NetconfError) -> None, datastore: str) -> None:
        _log.info("NETCONF lock", {"datastore": datastore})

        def _parse_response(c: Client, result: ?xml.Node):
            error: ?NetconfError = None
            if result is not None:
                if result.tag == "rpc-reply":
                    for child in result.children:
                        if child.tag == "rpc-error":
                            error_msg = "Lock operation failed"
                            for error_child in child.children:
                                if error_child.tag == "error-message" and error_child.text is not None:
                                    error_msg = error_child.text
                                    break
                            error = NetconfError(error_msg)
                            break
                        elif child.tag == "ok":
                            # Success case
                            break
                else:
                    error = NetconfError("Unexpected response type: " + result.tag)
            else:
                error = NetconfError("No response received for lock operation")

            cb(c, error)

        nc_nsdefs = [(None, NS_NC_1_0)]
        rpc(xml.Node("lock", nc_nsdefs, children=[
            xml.Node("target", children=[
                xml.Node(datastore)
            ])
        ]), _parse_response)

    def unlock(cb: action(Client, ?NetconfError) -> None, datastore: str) -> None:
        _log.info("NETCONF unlock", {"datastore": datastore})

        def _parse_response(c: Client, result: ?xml.Node):
            error: ?NetconfError = None
            if result is not None:
                if result.tag == "rpc-reply":
                    for child in result.children:
                        if child.tag == "rpc-error":
                            error_msg = "Unlock operation failed"
                            for error_child in child.children:
                                if error_child.tag == "error-message" and error_child.text is not None:
                                    error_msg = error_child.text
                                    break
                            error = NetconfError(error_msg)
                            break
                        elif child.tag == "ok":
                            # Success case
                            break
                else:
                    error = NetconfError("Unexpected response type: " + result.tag)
            else:
                error = NetconfError("No response received for unlock operation")

            cb(c, error)

        nc_nsdefs = [(None, NS_NC_1_0)]
        rpc(xml.Node("unlock", nc_nsdefs, children=[
            xml.Node("target", children=[
                xml.Node(datastore)
            ])
        ]), _parse_response)

    def get_schema(cb: action(Client, ?xml.Node) -> None, identifier: str, version: ?str=None, format: str="yang") -> None:
        _log.info("NETCONF get-schema", {"identifier": identifier, "version": version, "format": format})
        nc_nsdefs = [(None, NS_NC_1_0)]
        children = [xml.Node("identifier", text=identifier)]
        if version is not None:
            children.append(xml.Node("version", text=version))
        children.append(xml.Node("format", text=format))
        rpc(xml.Node("get-schema", nc_nsdefs, children=children), cb)

    def list_schemas(cb: action(Client, list[(identifier: ?str, version: ?str, format: ?str)]) -> None) -> None:
        """List available schemas and return parsed list of (identifier, version, format) tuples"""
        _log.info("NETCONF list-schemas")

        def _parse_response(c: Client, result: ?xml.Node):
            schemas = []
            if result is not None:
                if result.tag == "rpc-reply":
                    for child in result.children:
                        if child.tag == "data":
                            schemas = _parse_schemas_data(child)
            cb(c, schemas)

        def _parse_schemas_data(data_node: xml.Node) -> list[(?str, ?str, ?str)]:
            schemas = []
            for netconf_state in data_node.children:
                if netconf_state.tag == "netconf-state":
                    for schemas_node in netconf_state.children:
                        if schemas_node.tag == "schemas":
                            for schema in schemas_node.children:
                                if schema.tag == "schema":
                                    identifier = None
                                    version = None
                                    format = None
                                    for attr in schema.children:
                                        attr_text = attr.text
                                        if attr.tag == "identifier" and attr_text is not None:
                                            identifier = attr_text
                                        elif attr.tag == "version" and attr_text is not None:
                                            version = attr_text
                                        elif attr.tag == "format" and attr_text is not None:
                                            format = attr_text
                                    if identifier is not None:
                                        schemas.append((identifier, version, format))
            return schemas

        # Create filter for /netconf-state/schemas from ietf-netconf-monitoring
        filter_node = xml.Node("filter", None, None, [("type", "subtree")], [
            xml.Node("netconf-state",
                [(None, "urn:ietf:params:xml:ns:yang:ietf-netconf-monitoring")],
                children=[xml.Node("schemas")]
            )
        ], None, None)
        get(_parse_response, filter_node)

    def rpc_action(content: xml.Node, callback: action(Client, ?xml.Node) -> None) -> None:
        action_node = xml.Node("action", [(None, NS_YANG_ACTION)], None, [], [content], None, None)
        rpc(action_node, callback)

    def _send_hello() -> None:
        hello = """<?xml version="1.0" encoding="UTF-8"?>
        <hello xmlns="urn:ietf:params:xml:ns:netconf:base:1.0">
            <capabilities>
                <capability>urn:ietf:params:netconf:base:1.0</capability>
                <capability>urn:ietf:params:netconf:base:1.1</capability>
            </capabilities>
        </hello>"""
        buf: Buffer = Buffer()
        buf.write_str(hello)
        _send_message(buf)

    def handle_msg(msg: str) -> None:
        if len(msg) == 0:
            _log.debug("Ignoring empty message")
            return
        _log.trace("MSG:", {"msg": msg})
        try:
            root = xml.decode(msg)

            # Detect/update namespace prefix mode from server messages
            root_prefix = root.prefix
            if root_prefix is not None and root_prefix != nc_prefix:
                if nc_prefix is None:
                    _log.info("Server switched to explict namespace prefix mode", {"prefix": root_prefix})
                else:
                    _log.info("Explicit namespace prefix changed", {"previous": nc_prefix, "new": root_prefix})
                nc_prefix = root_prefix
            elif root_prefix is None and nc_prefix is not None:
                _log.info("Server switched to implicit namespace mode")
                nc_prefix = None

            if root.tag == "notification": # TODO: check namespace as well?
                _on_msg_notification(root)
            elif root.tag == "rpc-reply": # TODO: check namespace as well?
                _on_msg_rpc_reply(root)
            elif root.tag == "hello": # TODO: check namespace as well?
                _on_msg_hello(root)
            else:
                _log.warning("Unhandled message type:", {"root.tag": root.tag})
        except Exception as exc:
            _log.error("Failed to parse XML", {"msg": msg, "exc": exc})
            # TODO: I think we need to disconnect and start over, no?

    def _on_msg_hello(root: xml.Node) -> None:
        for n in root.children:
            if n.tag == "capabilities": # TODO: check namespace as well?
                capabilities.clear()
                for cap in n.children:
                    if cap.tag == "capability": # TODO: check namespace as well?
                        cap_body = cap.text # cap_body = cap.text.strip()
                        _on_capability(cap)
                    else:
                        pass # TODO: Warn?
            elif n.tag == "session-id": # TODO: check namespace as well?
                session_id = n.text
        state = "CONNECTED"
        on_connect(self, None)

    def _on_capability(cap: xml.Node) -> None:
        cap_text = cap.text # cap_text = cap.text.strip()
        if cap_text is not None:
            capabilities.append(cap_text)
            if cap_text == CAP_NC_1_1:
                _log.debug("NETCONF 1.1 supported, switching to chunked framing")
                framing = CHUNKED_FRAMING

    def _on_msg_rpc_reply(root: xml.Node) -> None:
        msg_id: ?str = None
        for attr_name, attr_val in root.attributes:
            # Handle both "message-id" and "nc:message-id" attributes
            if attr_name == "message-id" or attr_name == "nc:message-id":
                msg_id = attr_val
                break
            # Also handle other potential namespace prefixes
            elif attr_name.split(":", -1)[-1] == "message-id":
                msg_id = attr_val
                break

        if msg_id is not None:
            _cb = rpc_cbs.pop(msg_id)
            if _cb is not None:
                _log.debug("Received rpc-reply", {"msg-id": msg_id})
                _cb(self, root)
            else:
                _log.debug("Received rpc-reply with unexpected message-id", {"msg-id": msg_id})
        else:
            _log.debug("Received rpc-reply without message-id", None)

    def _on_msg_notification(root: xml.Node) -> None:
        _on_notif = on_notif
        if _on_notif is not None:
            _on_notif(self, root)

    def _on_legacy_msg_data() -> bool:
        i = recv_buf.find_bytes(LEGACY_SEPARATOR)
        if isinstance(i, int):
            _msg_data = recv_buf.read_bytes(i)
            if isinstance(_msg_data, bytes):
                recv_buf.skip_bytes(len(LEGACY_SEPARATOR))
                recv_buf.consume()
                handle_msg(_msg_data.decode())
                return True
        recv_buf.rewind()
        return False

    def _on_chunked_msg_data() -> bool:
        m = recv_buf.match_bytes(CHUNK_TAG_PREFIX)
        if isinstance(m, IncompleteReadError):
            recv_buf.rewind()
            return False
        elif isinstance(m, bool):
            if not m:
                on_connect(self, NetconfError("Invalid chunk framing data"))
                return False
            _len_text_len = recv_buf.find_bytes(CHUNK_TAG_POSTFIX)
            if isinstance(_len_text_len, IncompleteReadError):
                recv_buf.rewind()
                return False
            elif isinstance(_len_text_len, int):
                _len_text = recv_buf.read_bytes(_len_text_len)

                _skip = recv_buf.skip_bytes(len(CHUNK_TAG_POSTFIX))
                if isinstance(_skip, IncompleteReadError):
                    recv_buf.rewind()
                    return False
                elif isinstance(_skip, bool) and _skip:
                    if isinstance(_len_text, bytes):
                        if _len_text == CHUNK_TAG_END_OF_MSG:
                            _msg_data = chunk_buf.read_all_bytes()
                            chunk_buf.consume()
                            handle_msg(_msg_data.decode())
                            return True
                        else:
                            try:
                                l = int(_len_text.decode())
                                chunk = recv_buf.read_bytes(l)
                                chunk_buf.write_bytes(chunk)
                                recv_buf.consume()
                                return True
                            except IncompleteReadError:
                                recv_buf.rewind()
                                return False
        # TODO: FIXME: match_bytes should always return bytes or raise exception
        raise UnreachableError("Unexpected state in _on_chunked_msg_data")

    def _on_receive(c, data: bytes):
        #_log.trace("DATA:", {"data": data})
        recv_buf.write_bytes(data)
        try_read: bool = True
        # while recv_buf.has_unread_bytes() and try_read: # actonc: Name try_read is not in scope
        while recv_buf.has_unread_bytes():
            if not try_read:
                break
            if framing == SEPARATOR_FRAMING:
                try_read = _on_legacy_msg_data()
            elif framing == CHUNKED_FRAMING:
                try_read = _on_chunked_msg_data()
            else:
                try_read = False
                on_connect(self, NetconfError("Unknown framing type: {framing}"))

    def _on_connect(c, err: ?Exception):
        if err is not None:
            _log.error("Failed to connect", {"err": err})
            on_connect(self, err)
        else:
            _log.info("Connected", {"address": address, "port": port, "username": username})
            state = STATE_CONNECTED
            _send_hello()

    def _connect():
        c = ssh_client.Client(auth,
                              on_connect=_on_connect,
                              on_receive=_on_receive,
                              address=address,
                              username=username,
                              key=None,
                              password=password,
                              port=port,
                              subsystem="netconf",
                              log_handler=log_handler)

    _connect()

class NsMaps(object):
    def __init__(self, namespaces: list[(?str, str)], parent: ?NsMaps):
        self.nsmap = {_prefix if _prefix is not None else "": _ns for _prefix, _ns in namespaces}
        self.parent = parent

    def lookup(self, prefix: ?str) -> ?str:
        _inst = self
        while True:
            ns: ?str = self.nsmap.get(prefix if prefix is not None else "")
            if ns is not None:
                return ns
            _parent = _inst.parent
            if _parent is not None:
                _inst = _parent
            else:
                return None

class IncompleteReadError(Exception):
    def __init__(self):
        self.error_message = "Not enough data to read from buffer"
        self.msg = "Not enough data to read from buffer"

class Buffer(object):
    @property
    parts: list[bytes]
    @property
    i: int
    @property
    j: int
    @property
    total_bytes: int
    @property
    unread_bytes: int

    def __init__(self):
        self.parts = []
        self.i = 0
        self.j = 0
        self.total_bytes = 0
        self.unread_bytes = 0

    def write_bytes(self, data: bytes):
        l = len(data)
        self.parts.append(data)
        self.total_bytes += l
        self.unread_bytes += l

    def write_str(self, data: str):
        self.write_bytes(data.encode())

    def consume(self):
        #print("CONSUME!", self.i, self.j)
        if self.i > 0:
            # TODO: use a queue rather then list, i.e. parts: queue[bytes] to avoid copying/moving all elements in list
            self.parts = self.parts[self.i:]
            self.i = 0
        if self.j > 0:
            if len(self.parts) > 0:
                #self.parts[0] = self.parts[0][self.j:]
                parts: list[bytes] = self.parts # Workaround type-checker bug?
                parts[0] = parts[0][self.j:]
            self.j = 0
        self.total_bytes = self.unread_bytes
        #print("CONSUMED!", self.parts)

    def rewind(self):
        #print("REWIND!")
        self.i = 0
        self.j = 0
        self.unread_bytes = self.total_bytes

    def read_bytes_count(self) -> int:
        return self.total_bytes - self.unread_bytes

    def has_unread_bytes(self) -> bool:
        return self.unread_bytes > 0

    def assert_unread_bytes(self, count: int) -> value: # (bool | IncompleteReadError)
        # if self.unread_bytes < count:
        #     raise IncompleteReadError()
        if self.unread_bytes < count:
            return IncompleteReadError()
        else:
            return True

    def read_bytes(self, count: int) -> bytes: # (bytes | IncompleteReadError)
        #print("READ", count)
        #print("READ0!", self.i, self.j)
        if count > self.unread_bytes:
            raise IncompleteReadError()
        remaining = count
        acc = []
        parts: list[bytes] = self.parts # Workaround type-checker bug?
        while remaining > 0:
            #part = self.parts[self.i]
            part = parts[self.i]
            next_j = self.j + remaining
            chunk = part[self.j:next_j]
            chunk_len = len(chunk)
            remaining -= chunk_len
            if next_j >= len(part):
                self.i += 1
                next_j = 0
            self.j = next_j
            acc.append(chunk)
        self.unread_bytes -= count
        #print("READ1!", self.i, self.j)
        return bytes([]).join(acc)

    def read_all_bytes(self) -> bytes:
        b = self.read_bytes(self.unread_bytes)
        if isinstance(b, bytes):
            return b
        else:
            return bytes([])

    def skip_bytes(self, count: int) -> value: # (bool | IncompleteReadError):
        #print("SKIP", count)
        #print("SKIP0!", self.i, self.j)
        if count > self.unread_bytes:
            return IncompleteReadError()
        remaining = count
        parts: list[bytes] = self.parts # Workaround type-checker bug?
        while remaining > 0:
            #part = self.parts[self.i]
            part = parts[self.i]
            part_len = len(part)
            part_remain = part_len - self.j
            if remaining < part_remain:
                self.j += remaining
                break
            remaining -= part_remain
            self.i += 1
            self.j = 0
        self.unread_bytes -= count
        #print("SKIP0!", self.i, self.j)
        return True

    def find_bytes(self, pattern: bytes) -> value: # (index: int | err: IncompleteReadError)
        pattern_len = len(pattern)
        if pattern_len == 0:
            return 0
        elif pattern_len > self.unread_bytes:
            return IncompleteReadError()

        index = 0   # tracks the possible start of pattern
        _i = self.i # current part (index of self.parts)
        _j = self.j # current position in current part

        # Check if we have any parts to search
        if len(self.parts) == 0 or _i >= len(self.parts):
            return IncompleteReadError()

        part = self.parts[_i]
        part_len = len(part)
        while index <= self.unread_bytes - pattern_len:
            pattern_index = 0
            scan_i = _i
            scan_j = _j
            scan_part = part
            scan_part_len = part_len
            # Starting from index, scan the next pattern_len bytes for a pattern match
            while pattern_index < pattern_len:
                b = scan_part[scan_j]
                if b != pattern[pattern_index]:
                    break
                pattern_index += 1
                scan_j += 1
                if scan_j >= scan_part_len:
                    scan_i += 1
                    scan_j = 0
                    if scan_i >= len(self.parts):
                        # We've run out of parts while scanning
                        break
                    scan_part = self.parts[scan_i]
                    scan_part_len = len(scan_part)

            if pattern_index == pattern_len:
                # We matched all bytes in the pattern
                return index

            index += 1
            _j += 1
            if _j >= part_len:
                _i += 1
                _j = 0
                if _i >= len(self.parts):
                    return IncompleteReadError()
                part = self.parts[_i]
                part_len = len(part)

        return IncompleteReadError()

    def match_bytes(self, pattern: bytes) -> value: # (is_match: bool | err: IncompleteReadError)
        b = self.read_bytes(len(pattern))
        if isinstance(b, bytes):
            return b == pattern
        else:
            return b


################################################################################
## Tests                                                                      ##
################################################################################
#
# These test cases can be run with `acton test` but they require a running SSH
# server, for example `docker run -td -P ghcr.io/notconf/notconf` - grab the
# port and update test_port below, i.e.:
# - docker run -td --name notconf -P ghcr.io/notconf/notconf
# - docker inspect notconf | jq -r '.[0].NetworkSettings.Ports["830/tcp"][0].HostPort'
# - update test_port below with the port from the above command
# - acton test

test_port = 42830
test_address = "localhost"
test_username = "admin"
test_password = "admin"


actor _test_netconf(t: testing.EnvT):
    """Test SSH client towards a NETCONF server, like notconf
    """
    log = logging.Logger(t.log_handler)

    def _on_connect(c: Client, e: ?Exception):
        if e is not None:
            log.error("Failed to connect", {"error": e})
            t.failure(ValueError("Failed to connect to NETCONF server: {e}"))
        else:
            log.info("Connected to NETCONF server")
            for cap in c.get_capabilities():
                if cap.startswith("urn:ietf:params:netconf:base:1"):
                    log.info("Got NETCONF {cap} capability, looks reasonable, hello success")
                    c.get_config(_on_get_config)

    def _on_get_config(c: Client, result: ?xml.Node):
        log.info("<get-config> success")
        t.success()

    c = Client(t.env.auth,
                on_connect=_on_connect,
                address=test_address,
                username=test_username,
                key=None,
                password=test_password,
                port=test_port,
                log_handler=t.log_handler)


actor _test_get_schema(t: testing.EnvT):
    """Test SSH client get-schema operation towards a NETCONF server
    """
    log = logging.Logger(t.log_handler)

    def _on_connect(c: Client, e: ?Exception):
        if e is not None:
            log.error("Failed to connect", {"error": e})
            t.failure(ValueError("Failed to connect to NETCONF server: {e}"))
        else:
            log.info("Connected to NETCONF server")
            for cap in c.get_capabilities():
                if cap.startswith("urn:ietf:params:netconf:base:1"):
                    log.info("Got NETCONF {cap} capability, looks reasonable, hello success")
                    c.get_schema(_on_get_schema, "ietf-netconf")

    def _on_get_schema(c: Client, result: ?xml.Node):
        if result is not None:
            log.info("<get-schema> received response", {"result": result})
            t.success()
        else:
            log.error("<get-schema> received null response")
            t.failure(ValueError("get-schema returned null"))

    c = Client(t.env.auth,
                on_connect=_on_connect,
                on_notif=None,
                address=test_address,
                username=test_username,
                key=None,
                password=test_password,
                port=test_port,
                log_handler=t.log_handler)


actor _test_list_schemas(t: testing.EnvT):
    """Test listing available schemas from a NETCONF server
    """
    log = logging.Logger(t.log_handler)

    def _on_connect(c: Client, e: ?Exception):
        if e is not None:
            log.error("Failed to connect", {"error": e})
            t.failure(ValueError("Failed to connect to NETCONF server: {e}"))
        else:
            log.info("Connected to NETCONF server")
            c.list_schemas(_on_list_schemas)

    def _on_list_schemas(c: Client, schemas: list[(identifier: ?str, version: ?str, format: ?str)]):
        log.info("Received schemas list", {"count": len(schemas)})
        for schema in schemas:
            log.info("Schema found", {"identifier": schema.identifier, "version": schema.version, "format": schema.format})
        if len(schemas) > 0:
            t.success()
        else:
            log.warning("No schemas found")
            t.success()  # Still success even if no schemas

    c = Client(t.env.auth,
                on_connect=_on_connect,
                on_notif=None,
                address=test_address,
                username=test_username,
                key=None,
                password=test_password,
                port=test_port,
                log_handler=t.log_handler)


actor _test_lock_unlock(t: testing.EnvT):
    """Test lock and unlock operations on a datastore
    """
    log = logging.Logger(t.log_handler)

    def _on_connect(c: Client, e: ?Exception):
        if e is not None:
            log.error("Failed to connect", {"error": e})
            t.failure(ValueError("Failed to connect to NETCONF server: {e}"))
        else:
            log.info("Connected to NETCONF server")
            # First lock the running datastore
            c.lock(_on_lock, "running")

    def _on_lock(c: Client, error: ?NetconfError):
        if error is not None:
            log.error("Lock operation failed", {"error": error})
            t.failure(ValueError("Lock operation failed: {error}"))
        else:
            log.info("Lock operation successful")
            # Now unlock the datastore
            c.unlock(_on_unlock, "running")

    def _on_unlock(c: Client, error: ?NetconfError):
        if error is not None:
            log.error("Unlock operation failed", {"error": error})
            t.failure(ValueError("Unlock operation failed: {error}"))
        else:
            log.info("Unlock operation successful")
            log.info("Lock and unlock test completed successfully")
            t.success()

    c = Client(t.env.auth,
                on_connect=_on_connect,
                on_notif=None,
                address=test_address,
                username=test_username,
                key=None,
                password=test_password,
                port=test_port,
                log_handler=t.log_handler)


def _test_buffer_find_bytes_start():
    """Test finding 'hello' at beginning of buffer"""
    buf = Buffer()
    buf.write_str("hello world, this is bob")
    result = buf.find_bytes("hello".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 0, "Should find 'hello' at position 0")


def _test_buffer_find_bytes_mid():
    """Test finding 'world' in middle of buffer"""
    buf = Buffer()
    buf.write_str("hello world, this is bob")
    result = buf.find_bytes("world".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 6, "Should find 'world' at position 6")


def _test_buffer_find_bytes_end():
    """Test finding 'world' in middle of buffer"""
    buf = Buffer()
    buf.write_str("hello world, this is bob")
    result = buf.find_bytes("bob".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 21, "Should find 'bob' at position 21")


def _test_buffer_find_bytes_one():
    """Test finding space character in buffer"""
    buf = Buffer()
    buf.write_str("hello world")
    result = buf.find_bytes(" ".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 5, "Should find space at position 5")


def _test_buffer_find_bytes_not_found():
    """Test pattern not found returns IncompleteReadError"""
    buf = Buffer()
    buf.write_str("hello world")
    result = buf.find_bytes("xyz".encode())
    testing.assertTrue(isinstance(result, IncompleteReadError), "Should return IncompleteReadError for non-existent pattern")


# Test overlapping patterns

def _test_buffer_find_bytes_separator_single_bracket():
    """Test finding NETCONF separator preceded by single ]"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("]]]>]]>")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 1, "Should find separator at position 1 after single ]")


def _test_buffer_find_bytes_separator_double_bracket():
    """Test finding NETCONF separator preceded by double ]]"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("]]]]>]]>")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 2, "Should find separator at position 2 after double ]]")


def _test_buffer_find_bytes_separator_mixed_prefix():
    """Test finding NETCONF separator preceded by ]>]"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("]>]]]>]]>")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 3, "Should find separator at position 3 after ]>]")


def _test_buffer_find_bytes_split_across_two_parts():
    """Test finding pattern split across two buffer parts"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("data]]")
    buf.write_str(">]]>more")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 4, "Should find separator split across parts")


def _test_buffer_find_bytes_split_with_overlap():
    """Test finding pattern with overlapping character before split"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("data]")
    buf.write_str("]]>]]>more")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 5, "Should find separator with ] before split")


def _test_buffer_find_bytes_across_three_parts():
    """Test finding pattern split across 3 buffer parts"""
    buf = Buffer()
    buf.write_str("ab")
    buf.write_str("cd")
    buf.write_str("ef")
    result = buf.find_bytes("cde".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 2, "Should find pattern across 3 parts")


def _test_buffer_find_bytes_separator_four_parts():
    """Test finding NETCONF separator split across 4 parts"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("]")
    buf.write_str("]>")
    buf.write_str("]")
    buf.write_str("]>")
    result = buf.find_bytes(separator)
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 0, "Should find separator split across 4 parts")


def _test_buffer_find_bytes_empty_pattern():
    """Test finding empty pattern returns 0"""
    buf = Buffer()
    buf.write_str("test")
    result = buf.find_bytes("".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for empty pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 0, "Empty pattern should return 0")


def _test_buffer_find_bytes_pattern_too_long():
    """Test pattern longer than buffer returns IncompleteReadError"""
    buf = Buffer()
    buf.write_str("short")
    result = buf.find_bytes("very long pattern".encode())
    testing.assertTrue(isinstance(result, IncompleteReadError), "Pattern longer than buffer should return IncompleteReadError")


def _test_buffer_find_bytes_pattern_at_end():
    """Test finding pattern at the very end of buffer"""
    buf = Buffer()
    buf.write_str("data]]>]]>")
    result = buf.find_bytes("]]>]]>".encode())
    testing.assertTrue(isinstance(result, int), "Should return int for found pattern")
    if isinstance(result, int):
        testing.assertEqual(result, 4, "Should find pattern at end of buffer")


def _test_buffer_find_bytes_first_separator():
    """Test finding first separator in buffer"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("first]]>]]>second]]>]]>third")
    pos = buf.find_bytes(separator)
    testing.assertTrue(isinstance(pos, int), "Should return int for found pattern")
    if isinstance(pos, int):
        testing.assertEqual(pos, 5, "Should find first separator at position 5")


def _test_buffer_find_bytes_after_consume():
    """Test finding separator after consume operation"""
    buf = Buffer()
    separator = "]]>]]>".encode()
    buf.write_str("first]]>]]>second]]>]]>third")

    # Find and skip past first separator
    pos = buf.find_bytes(separator)
    if isinstance(pos, int):
        skip_result = buf.skip_bytes(pos + len(separator))
        if isinstance(skip_result, bool):
            buf.consume()

            # Find second separator
            pos2 = buf.find_bytes(separator)
            testing.assertTrue(isinstance(pos2, int), "Should return int for found pattern")
            if isinstance(pos2, int):
                testing.assertEqual(pos2, 6, "Should find second separator at position 6 after consume")
